{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Importing Libraries"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-11-19T08:33:47.267879Z","iopub.status.busy":"2022-11-19T08:33:47.267443Z","iopub.status.idle":"2022-11-19T08:33:51.248403Z","shell.execute_reply":"2022-11-19T08:33:51.247154Z","shell.execute_reply.started":"2022-11-19T08:33:47.267794Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import glob\n","import os\n","\n","import librosa\n","import librosa.display\n","\n","\n","import torch\n","from torch import nn\n","from torchvision import models, transforms, datasets\n","\n","from time import time\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{},"source":["## Defining Parameters"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-11-19T08:33:51.251297Z","iopub.status.busy":"2022-11-19T08:33:51.250613Z","iopub.status.idle":"2022-11-19T08:33:51.371742Z","shell.execute_reply":"2022-11-19T08:33:51.370766Z","shell.execute_reply.started":"2022-11-19T08:33:51.251253Z"},"trusted":true},"outputs":[],"source":["seed = 411\n","np.random.seed(seed)\n","\n","path = \"/Users/kemalcankucuk/Library/CloudStorage/OneDrive-KocUniversitesi/Okul/4. Sınıf/1. Dönem/COMP411/Project/comp411-project/gtzan_dataset\"\n","\n","path_audio_files = path + \"/Users/kemalcankucuk/Library/CloudStorage/OneDrive-KocUniversitesi/Okul/4. Sınıf/1. Dönem/COMP411/Project/comp411-project/gtzan_dataset/genres_original\"\n","\n","path_imgs = \"./mel_spectrogram_imgs/\"\n","\n","batch_size = 32\n","\n","hop_length = 512\n","\n","n_fft = 2048\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","genre_dict = {\"blues\":0,\"classical\":1,\"country\":2,\"disco\":3,\"hiphop\":4,\"jazz\":5,\"metal\":6,\"pop\":7,\"reggae\":8,\"rock\":9}"]},{"cell_type":"markdown","metadata":{},"source":["## Transforming Audio Files into Mel Spectograms and Saving the Images"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-11-19T08:33:51.374233Z","iopub.status.busy":"2022-11-19T08:33:51.373886Z","iopub.status.idle":"2022-11-19T08:38:22.197650Z","shell.execute_reply":"2022-11-19T08:38:22.196607Z","shell.execute_reply.started":"2022-11-19T08:33:51.374205Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Transforming the Audio Files into Mel Spectrograms:\n","\t blues\n","\t classical\n","\t country\n","\t disco\n","\t hiphop\n","\t jazz\n","\t metal\n","\t pop\n","\t reggae\n","\t rock\n","Saving the Mel Spectrogram Images:\n","\t blues\n","\t classical\n","\t country\n","\t disco\n","\t hiphop\n","\t jazz\n","\t metal\n","\t pop\n","\t reggae\n","\t rock\n"]}],"source":["print(\"Transforming the Audio Files into Mel Spectrograms:\")\n","\n","mel_spectogram_data = {}\n","for genre in genre_dict.keys():\n","    print(\"\\t\",genre)\n","    \n","    mel_spectogram_data[genre] = []\n","\n","    for name in glob.glob(path_audio_files + genre + \"/*\"):\n","        \n","        if(name != \"../input/gtzan-dataset-music-genre-classification/Data/genres_original/jazz/jazz.00054.wav\"):\n","        \n","            data,sampling_rate = librosa.load(name)\n","\n","            mel_spec = librosa.feature.melspectrogram(y = data.ravel(), sr=sampling_rate,hop_length = hop_length)\n","            mel_spec_db = librosa.amplitude_to_db(mel_spec, ref=np.max)\n","\n","            mel_spectogram_data[genre].append(mel_spec_db)\n","            \n","\n","print(\"Saving the Mel Spectrogram Images:\")\n","            \n","#os.mkdir(path_imgs)\n","path_imgs = \"/Users/kemalcankucuk/Library/CloudStorage/OneDrive-KocUniversitesi/Okul/4. Sınıf/1. Dönem/COMP411/Project/comp411-project/gtzan_dataset/images_custom\"\n","for genre in genre_dict.keys():\n","    print(\"\\t\",genre)\n","    try:\n","        os.mkdir(path_imgs + genre)\n","    except:\n","        pass\n","    \n","    for i in range(len(mel_spectogram_data[genre])):\n","\n","        fig, ax = plt.subplots(1, figsize=(12,8))\n","\n","        img = librosa.display.specshow(mel_spectogram_data[genre][i], sr = sampling_rate, hop_length = hop_length,cmap = 'cool',ax=ax)\n","\n","        fig.savefig(path_imgs + genre + \"/\" + genre + \"_\" + str(i) + \".png\")\n","        \n","        plt.close()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-11-19T08:38:22.200942Z","iopub.status.busy":"2022-11-19T08:38:22.200274Z","iopub.status.idle":"2022-11-19T08:38:24.238217Z","shell.execute_reply":"2022-11-19T08:38:24.237069Z","shell.execute_reply.started":"2022-11-19T08:38:22.200899Z"},"trusted":true},"outputs":[{"data":{"text/plain":["22"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["import gc\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["## Load and Transform the Data"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-11-19T08:38:24.240701Z","iopub.status.busy":"2022-11-19T08:38:24.240163Z","iopub.status.idle":"2022-11-19T08:38:24.283872Z","shell.execute_reply":"2022-11-19T08:38:24.282798Z","shell.execute_reply.started":"2022-11-19T08:38:24.240660Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of Train:800; Length of Val:100; Length of Test:99\n","CPU times: user 26.7 ms, sys: 24.1 ms, total: 50.8 ms\n","Wall time: 92.3 ms\n"]}],"source":["%%time\n","\n","# Define Tranforms\n","train_transforms = transforms.Compose([\n","    #transforms.Resize(224),\n","    transforms.ToTensor(),\n","    \n","    transforms.Normalize(mean=[0.4931, 0.9151, 0.9960], std=[0.4495, 0.1716, 0.0602])\n","])\n","\n","test_transforms = transforms.Compose([\n","    #transforms.Resize(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.4931, 0.9151, 0.9960], std=[0.4495, 0.1716, 0.0602])\n","])\n","\n","# Load the data\n","train_dataset = datasets.ImageFolder(path_imgs, transform = train_transforms)\n","val_dataset = datasets.ImageFolder(path_imgs, transform = test_transforms)\n","test_dataset = datasets.ImageFolder(path_imgs, transform = test_transforms)\n","\n","\n","torch.manual_seed(1)\n","num_train_samples = len(train_dataset)\n","#num_train_samples = 20000\n","\n","# Permute the data\n","indices = torch.randperm(num_train_samples)\n","\n","# Split the data into Train and Validation\n","train_testval_split = 0.2\n","train_split = int(num_train_samples * train_testval_split)\n","val_split = int(train_split * 0.5)\n","\n","train_subset = torch.utils.data.Subset(train_dataset, indices[train_split:])\n","val_subset = torch.utils.data.Subset(val_dataset, indices[val_split:train_split])\n","test_subset = torch.utils.data.Subset(test_dataset, indices[:val_split])\n","\n","\n","print(f\"Length of Train:{len(train_subset)}; Length of Val:{len(val_subset)}; Length of Test:{len(test_subset)}\")\n","\n","\n","\n","# Make DataLoaders \n","train_dataloader = torch.utils.data.DataLoader(\n","    dataset=train_subset, \n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","val_dataloader = torch.utils.data.DataLoader(\n","    dataset=val_subset,\n","    batch_size=batch_size,\n","    shuffle=False\n",")\n","\n","# Classes\n","classes = train_dataloader.dataset.dataset.classes"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-11-19T08:38:24.285537Z","iopub.status.busy":"2022-11-19T08:38:24.285118Z","iopub.status.idle":"2022-11-19T08:38:25.332422Z","shell.execute_reply":"2022-11-19T08:38:25.331125Z","shell.execute_reply.started":"2022-11-19T08:38:24.285501Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["mean and std: \n"," tensor([ 0.6516, -2.1342, -5.4688]) tensor([0.6172, 2.3201, 4.8507])\n"]}],"source":["def mean_std(loader):\n","    images, lebels = next(iter(loader))\n","    # shape of images = [b,c,w,h]\n","    mean, std = images.mean([0,2,3]), images.std([0,2,3])\n","    return mean, std\n","\n","mean, std = mean_std(train_dataloader)\n","print(\"mean and std: \\n\", mean, std)"]},{"cell_type":"markdown","metadata":{},"source":["## ResNet18 - Transfer Learning"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-11-19T08:38:25.334802Z","iopub.status.busy":"2022-11-19T08:38:25.334406Z","iopub.status.idle":"2022-11-19T08:38:28.076103Z","shell.execute_reply":"2022-11-19T08:38:28.075099Z","shell.execute_reply.started":"2022-11-19T08:38:25.334763Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n","/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/kemalcankucuk/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:08<00:00, 5.74MB/s]\n"]}],"source":["# Load a Pretrained Model\n","resnet = models.resnet18(pretrained=True)\n","\n","# Fix the trainable parameters\n","for parameter in resnet.parameters():\n","    parameter.requires_grad = False\n","    \n","    \n","# Number of Input Features in the Last Fully Connected Layer\n","in_features = resnet.fc.in_features\n","\n","# Replacing the Last Fully Connected Layer\n","fc = nn.Linear(in_features=in_features, out_features=len(classes))\n","resnet.fc = fc\n","\n","\n","# Updating the Weights and Bias of the last layer\n","params_to_update = []\n","for name, param in resnet.named_parameters():\n","    if param.requires_grad == True:\n","        params_to_update.append(param)\n","\n","# Define the Loss and Optimizer Functions\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params_to_update, lr=0.001)"]},{"cell_type":"markdown","metadata":{},"source":["## Training the Model"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-11-19T08:38:28.078017Z","iopub.status.busy":"2022-11-19T08:38:28.077654Z","iopub.status.idle":"2022-11-19T08:38:28.091461Z","shell.execute_reply":"2022-11-19T08:38:28.090340Z","shell.execute_reply.started":"2022-11-19T08:38:28.077981Z"},"trusted":true},"outputs":[],"source":["def train(model, criterion, optimizer, train_dataloader,test_dataloader,print_every,num_epoch):\n","    \n","    steps = 0\n","    train_losses, val_losses = [], []\n","    \n","    model.to(device)\n","    for epoch in tqdm(range(num_epoch)):\n","        running_loss = 0\n","        correct_train = 0\n","        total_train = 0\n","        start_time = time()\n","        iter_time = time()\n","        \n","        model.train()\n","        for i, (images, labels) in enumerate(train_dataloader):\n","            steps += 1\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            \n","            # Forward pass\n","            output = model(images)\n","            loss = criterion(output, labels)\n","\n","            correct_train += (torch.max(output, dim=1)[1] == labels).sum()\n","            total_train += labels.size(0)\n","            \n","            # Backward and optimize\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","            \n","            # Logging\n","            if steps % print_every == 0:\n","                print(f'Epoch [{epoch + 1}]/[{num_epoch}]. Batch [{i + 1}]/[{len(train_dataloader)}].', end=' ')\n","                print(f'Train loss {running_loss / steps:.3f}.', end=' ')\n","                print(f'Train acc {correct_train / total_train * 100:.3f}.', end=' ')\n","                with torch.no_grad():\n","                    model.eval()\n","                    correct_val, total_val = 0, 0\n","                    val_loss = 0\n","                    for images, labels in test_dataloader:\n","                        images = images.to(device)\n","                        labels = labels.to(device)\n","                        output = model(images)\n","                        loss = criterion(output, labels)\n","                        val_loss += loss.item()\n","                        \n","                        correct_val += (torch.max(output, dim=1)[1] == labels).sum()\n","                        total_val += labels.size(0)\n","\n","                print(f'Val loss {val_loss / len(test_dataloader):.3f}. Val acc {correct_val / total_val * 100:.3f}.', end=' ')\n","                print(f'Took {time() - iter_time:.3f} seconds')\n","                iter_time = time()\n","                \n","                \n","                train_losses.append(running_loss / total_train)\n","                val_losses.append(val_loss / total_val)\n","\n","\n","        print(f'Epoch took {time() - start_time}') \n","        torch.save(model, f'checkpoint_{correct_val / total_val * 100:.2f}')\n","        \n","    return model, train_losses, val_losses"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-11-19T08:38:28.095013Z","iopub.status.busy":"2022-11-19T08:38:28.093245Z","iopub.status.idle":"2022-11-19T09:38:05.308334Z","shell.execute_reply":"2022-11-19T09:38:05.302884Z","shell.execute_reply.started":"2022-11-19T08:38:28.094984Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/100 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1]/[100]. Batch [25]/[25]. Train loss 2.184. Train acc 22.750. Val loss 2.021. Val acc 36.000. Took 159.701 seconds\n","Epoch took 159.70740485191345\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 1/100 [02:40<4:24:52, 160.53s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [2]/[100]. Batch [25]/[25]. Train loss 0.935. Train acc 38.375. Val loss 1.747. Val acc 47.000. Took 152.739 seconds\n","Epoch took 152.7455699443817\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 2/100 [05:55<4:50:25, 177.81s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/var/folders/z_/xl83rncn74z5j74lky24_9br0000gn/T/ipykernel_39976/3071938866.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/var/folders/z_/xl83rncn74z5j74lky24_9br0000gn/T/ipykernel_39976/1506505360.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_dataloader, test_dataloader, print_every, num_epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    166\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[1;32m    167\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                             return_indices=self.return_indices)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["print_every = 25\n","num_epoch = 100\n","\n","resnet, train_losses, val_losses = train(\n","    model=resnet,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    train_dataloader=train_dataloader,\n","    test_dataloader=val_dataloader,\n","    print_every=print_every,\n","    num_epoch=num_epoch\n",")\n","\n","\n","plt.plot(train_losses, label='Training loss')\n","plt.plot(val_losses, label='Validation loss')\n","plt.legend(frameon=False)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Testing"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-11-19T09:38:21.851197Z","iopub.status.busy":"2022-11-19T09:38:21.850805Z","iopub.status.idle":"2022-11-19T09:38:24.988589Z","shell.execute_reply":"2022-11-19T09:38:24.987527Z","shell.execute_reply.started":"2022-11-19T09:38:21.851165Z"},"trusted":true},"outputs":[],"source":["y_test = []\n","y_pred = []\n","for img, label in test_subset:\n","    img = torch.Tensor(img)\n","    img = img.to(device)\n","    resnet.eval()\n","    prediction = resnet(img[None])\n","    \n","    final_pred = classes[torch.max(prediction, dim=1)[1]]\n","    \n","    #print(label, genre_dict[final_pred])\n","    \n","    y_test.append(label)\n","    y_pred.append(genre_dict[final_pred])\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-11-19T09:41:11.523357Z","iopub.status.busy":"2022-11-19T09:41:11.522994Z","iopub.status.idle":"2022-11-19T09:41:11.531481Z","shell.execute_reply":"2022-11-19T09:41:11.530324Z","shell.execute_reply.started":"2022-11-19T09:41:11.523326Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 66.66666666666667\n"]}],"source":["print(\"Accuracy:\",(100*(np.array(y_test) == np.array(y_pred)).sum()/len(y_test)))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9 (v3.7.9:13c94747c7, Aug 15 2020, 01:31:08) \n[Clang 6.0 (clang-600.0.57)]"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":4}
